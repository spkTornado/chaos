{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911496ec-4fda-433d-b824-0ba57594ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Description: Convert any annotated (by snpEff and snpShift)\n",
    "into.json format. Will be very helpful for the inte\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13ec05f2-26ad-4d48-80d1-53b656db0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8258bff4-6da6-47a5-8807-77d0d3322914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iVCF = '/Users/shashank.katiyar/projects/vcfAnnotation/antiADARhits_ENST00000226574.snpeff.snpsift.dbsnp.vcf'\n",
    "#iVCF='/Users/shashank.katiyar/projects/vcfAnnotation/ADARhits_ENST00000226574.snpeff.snpsift.dbsnp.clinvar.vcf'\n",
    "iVCF='/Users/shashank.katiyar/projects/vcfAnnotation/antiADARhits_ENST00000226574.snpeff.snpsift.dbsnp.clinvar.vcf'\n",
    "odir = '/Users/shashank.katiyar/projects/vcfAnnotation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "40f189d3-6dd0-46b8-8e21-7ef3be07ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getID(idData):\n",
    "    '''\n",
    "    There can be multiple varrIDs after annotating with dbSNP;\n",
    "    One from transcript2vcf and another from dbSNP\n",
    "    This function returns the transcript2vcf generated id.\n",
    "    This can be helpful later to integrate with the Benchling/Intake sheet\n",
    "    '''\n",
    "    return idData.split(';')[0]\n",
    "\n",
    "def getHighestPathogenicityPrediction(inputPredictionsStates):\n",
    "    '''\n",
    "    Given the multiple predictions from a pathgenicity predictor,\n",
    "    return the highest. Eg. 'D,D,T,T,D' --> 'D'\n",
    "    Order is : 'A'|'D' > 'P'|'B'|'T'|'N' > 'U'\n",
    "    '''\n",
    "    \n",
    "    #damagin_chars_dict = {'A','D'}\n",
    "    #tolerated_chars_dict = {'P','B','T','N'}\n",
    "    \n",
    "    if 'D' in inputPredictionsStates or 'A' in inputPredictionsStates:\n",
    "        return 'D'\n",
    "    elif 'T' in inputPredictionsStates or\\\n",
    "         'P' in inputPredictionsStates or\\\n",
    "         'B' in inputPredictionsStates or\\\n",
    "         'N' in inputPredictionsStates:\n",
    "        return 'T'\n",
    "    else:\n",
    "        return 'U'\n",
    "\n",
    "def verifyVarID(iVarID, varID_alt):\n",
    "    if not iVarID:    # This should not happen\n",
    "        print(\"\\nNo varID identified for the variant: \", varID_alt)\n",
    "        sys.exit()\n",
    "        \n",
    "varDict = {}\n",
    "concise_varDict = {}\n",
    "\n",
    "\n",
    "with open(iVCF) as ivcf:\n",
    "    for line in ivcf:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        lineData = line.replace(\" \",\"\").replace(\"\\n\",\"\").replace(\"\\r\",\"\").split(\"\\t\")\n",
    "        \n",
    "        chrom, pos = lineData[:2]\n",
    "        ref, alt = lineData[3:5]\n",
    "        \n",
    "        varID_alt = getID(lineData[2])    #we will use c. to use an id\n",
    "        \n",
    "        varID = False\n",
    "        \n",
    "        infoData_list = lineData[7].split(\";\")\n",
    "        \n",
    "        for infoField in infoData_list:\n",
    "            if infoField.startswith('ANN'):    # Info annotation by snpEff\n",
    "                annoFields_list = infoField.split(',')\n",
    "                \n",
    "                # Because there can be multiple annotations for the same variant\n",
    "                effect = []\n",
    "                impact = []\n",
    "                gene = []\n",
    "                geneID = []\n",
    "                pdot = []\n",
    "                cdot = []\n",
    "                \n",
    "                \n",
    "                for multiAnnoAnnotation in annoFields_list:\n",
    "                    annoField_list = multiAnnoAnnotation.split('|')\n",
    "\n",
    "                    effect.append(annoField_list[1])\n",
    "                    impact.append(annoField_list[2])\n",
    "                    gene.append(annoField_list[3])\n",
    "                    geneID.append(annoField_list[4])\n",
    "                    cdot.append(annoField_list[9])\n",
    "                    pdot.append(annoField_list[10])\n",
    "                    \n",
    "                \n",
    "                effect = \";\".join(effect)\n",
    "                impact = \";\".join(impact)\n",
    "                gene = \";\".join(gene)\n",
    "                geneID = \";\".join(geneID)\n",
    "                pdot = \";\".join(pdot)\n",
    "                cdot = \";\".join(cdot)\n",
    "                \n",
    "                varID = cdot\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                # update the dicts with coordinates\n",
    "                varDict[varID] = {'chrom': chrom,\n",
    "                              'tpos': varID_alt.split(\"-\")[-1],\n",
    "                              'gpos': pos,\n",
    "                              'ref': ref,\n",
    "                              'alt': alt}\n",
    "\n",
    "                concise_varDict[varID] = {'chrom': chrom,\n",
    "                              'tpos': varID_alt.split(\"-\")[-1],\n",
    "                              'gpos': pos,\n",
    "                              'ref': ref,\n",
    "                              'alt': alt} \n",
    "                \n",
    "                # initialize main categories\n",
    "                varDict[varID]['pathogenicity'] = []\n",
    "                varDict[varID]['conserved'] = []\n",
    "                varDict[varID]['popAF'] = []\n",
    "\n",
    "                # add to the dictionary\n",
    "                varDict[varID]['effect'] =  effect\n",
    "                varDict[varID]['impact'] = impact\n",
    "                varDict[varID]['gene'] = gene                \n",
    "                varDict[varID]['geneID'] = geneID               \n",
    "                varDict[varID]['pdot'] = pdot\n",
    "                varDict[varID]['cdot'] = cdot\n",
    "                \n",
    "                \n",
    "                concise_varDict[varID]['effect'] = effect\n",
    "                concise_varDict[varID]['pdot'] = pdot\n",
    "                concise_varDict[varID]['cdot'] = cdot\n",
    "                concise_varDict[varID]['impact'] = impact \n",
    "                               \n",
    "                \n",
    "            elif infoField.startswith('RS='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                varDict[varID]['rsid'] = infoField.replace(\"RS=\",'')\n",
    "            \n",
    "            # Note about annotations:\n",
    "            # From here onwards, 'https://varianttools.sourceforge.net/Annotation/DbNSFP' to see\n",
    "            # the explanations of the annotations\n",
    "            \n",
    "            elif infoField.startswith('dbNSFP_GERP___NR='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                varDict[varID]['GERP_NR'] = infoField.replace(\"dbNSFP_GERP___NR=\",'')\n",
    "            \n",
    "            \n",
    "            elif infoField.startswith('dbNSFP_GERP___RS='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                gerpRS_raw = np.mean([float(x) for x in infoField.replace(\"dbNSFP_GERP___RS=\",'').split(',')])\n",
    "                # range is: -12.3 - 6.17\n",
    "                # let's normalize it between 0-1; minMax normalization\n",
    "                gerpRS = (gerpRS_raw - (-12.3)) / (6.17 - (-12.3))\n",
    "                \n",
    "                varDict[varID]['GERP_RS'] = gerpRS\n",
    "                varDict[varID]['conserved'].append(gerpRS)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_MutationTaster_pred='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                mutationTester_pred = getHighestPathogenicityPrediction(infoField.replace(\"dbNSFP_MutationTaster_pred=\",''))\n",
    "                varDict[varID]['MutationTaster_pred'] = mutationTester_pred\n",
    "                varDict[varID]['pathogenicity'].append(mutationTester_pred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_PROVEAN_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                priveanPred = getHighestPathogenicityPrediction(infoField.replace(\"dbNSFP_PROVEAN_pred=\",''))\n",
    "                varDict[varID]['PROVEAN_pred'] = priveanPred\n",
    "                varDict[varID]['pathogenicity'].append(priveanPred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_SIFT_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                siftPred = getHighestPathogenicityPrediction(infoField.replace(\"dbNSFP_SIFT_pred=\",''))\n",
    "                varDict[varID]['SIFT_pred'] = siftPred\n",
    "                varDict[varID]['pathogenicity'].append(siftPred)\n",
    "            \n",
    "            elif infoField.startswith('dbNSFP_MetaSVM_pred='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                metaSVM_pred = getHighestPathogenicityPrediction(infoField.replace(\"dbNSFP_MetaSVM_pred=\",''))\n",
    "                varDict[varID]['MetaSVM_pred'] = metaSVM_pred\n",
    "                varDict[varID]['pathogenicity'].append(metaSVM_pred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_Uniprot_acc='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                varDict[varID]['Uniprot_ids'] = infoField.replace(\"dbNSFP_Uniprot_acc=\",'')\n",
    "                concise_varDict['Uniprot_ids'] = infoField.replace(\"dbNSFP_Uniprot_acc=\",'')\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_phastCons100way_vertebrate='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                # Source: https://genome.ucsc.edu/cgi-bin/hgTables?db=hg38&hgta_group=compGeno&hgta_track=cons100way&hgta_table=phastCons100way&hgta_doSchema=describe+table+schema\n",
    "                # Source: http://compgen.cshl.edu/phast/phastCons-HOWTO.html\n",
    "                # Treat is as the conservation score of the nucleotide base in vertibrates\n",
    "                # Higher the score, more conserved the nucleotide base is\n",
    "                phastCons100 = np.mean([float(x) for x in infoField.replace(\"dbNSFP_phastCons100way_vertebrate=\",'').split(',')])\n",
    "                varDict[varID]['phastCons100way_conservationScore'] = phastCons100\n",
    "                varDict[varID]['conserved'].append(phastCons100)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_LRT_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                lrtPred = infoField.replace(\"dbNSFP_LRT_pred=\",'')\n",
    "                varDict[varID]['LRT_pred'] = lrtPred\n",
    "                varDict[varID]['pathogenicity'].append(lrtPred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_MutationAssessor_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                mutationAssessorPred = infoField.replace(\"dbNSFP_MutationAssessor_pred=\",'')\n",
    "                varDict[varID]['MutationAssessor_pred'] = mutationAssessorPred\n",
    "                varDict[varID]['pathogenicity'].append(mutationAssessorPred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_FATHMM_pred='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                fathmmPred = infoField.replace(\"dbNSFP_FATHMM_pred=\",'')\n",
    "                varDict[varID]['FATHMM_pred'] = fathmmPred\n",
    "                varDict[varID]['pathogenicity'].append(fathmmPred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_Polyphen2_HVAR_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                polyPhen2_hvarPred = infoField.replace(\"dbNSFP_Polyphen2_HVAR_pred=\",'')\n",
    "                varDict[varID]['Polyphen2_HVAR_pred'] = polyPhen2_hvarPred\n",
    "                varDict[varID]['pathogenicity'].append(polyPhen2_hvarPred)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_Polyphen2_HDIV_pred='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                polyPhen2_hdivPred = infoField.replace(\"dbNSFP_Polyphen2_HDIV_pred=\",'')\n",
    "                varDict[varID]['Polyphen2_HDIV_pred'] = polyPhen2_hdivPred\n",
    "                varDict[varID]['pathogenicity'].append(polyPhen2_hdivPred)\n",
    "                \n",
    "            # Population AF\n",
    "            elif infoField.startswith('dbNSFP_ESP6500_AA_AF='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                pop_ESP6500_AA_AF = float(infoField.replace(\"dbNSFP_ESP6500_AA_AF=\",''))\n",
    "                varDict[varID]['ESP6500_AA_AF'] = pop_ESP6500_AA_AF\n",
    "                varDict[varID]['popAF'].append(pop_ESP6500_AA_AF)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_ESP6500_EA_AF='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                pop_ESP6500_EA_AF = float(infoField.replace(\"dbNSFP_ESP6500_EA_AF=\",''))\n",
    "                varDict[varID]['ESP6500_EA_AF'] = pop_ESP6500_EA_AF\n",
    "                varDict[varID]['popAF'].append(pop_ESP6500_EA_AF)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_ExAC_AF='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                pop_ExAC_AF = float(infoField.replace(\"dbNSFP_ExAC_AF=\",''))\n",
    "                varDict[varID]['ExAC_AF'] = pop_ExAC_AF\n",
    "                varDict[varID]['popAF'].append(pop_ExAC_AF)\n",
    "                \n",
    "            elif infoField.startswith('dbNSFP_1000Gp3_AF='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                pop_1000Gp3_AF = float(infoField.replace(\"dbNSFP_1000Gp3_AF=\",''))\n",
    "                varDict[varID]['1000Gp3_AF'] = pop_1000Gp3_AF\n",
    "                try:\n",
    "                    varDict[varID]['popAF'].append(pop_1000Gp3_AF)\n",
    "                except KeyError:\n",
    "                    print(varID_alt)\n",
    "                    print(varDict[varID])\n",
    "                    raise\n",
    "                          \n",
    "            # Domain effects\n",
    "            elif infoField.startswith('dbNSFP_Interpro_domain='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                domainInfo = infoField.replace(\"dbNSFP_Interpro_domain=\",'')\n",
    "                if 'DNA-binding' in domainInfo:\n",
    "                    varDict[varID]['Interpro_domain'] = 'DNA-binding'\n",
    "                    concise_varDict[varID]['Interpro_domain'] = 'DNA-binding'\n",
    "                elif  'protein-binding' in domainInfo.lower():\n",
    "                    varDict[varID]['Interpro_domain'] = 'Protein-binding'\n",
    "                    concise_varDict[varID]['Interpro_domain'] = 'Protein-binding'\n",
    "                else:\n",
    "                    varDict[varID]['Interpro_domain'] = infoField\n",
    "                    concise_varDict[varID]['Interpro_domain'] = infoField\n",
    "            \n",
    "            # Clinvar annotations\n",
    "            elif infoField.startswith('ALLELEID='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                clinvarID = int(infoField.replace(\"ALLELEID=\",''))\n",
    "                varDict[varID]['clinvarID'] = clinvarID\n",
    "            \n",
    "            elif infoField.startswith('CLNDISDB='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                varDict[varID]['clinvarSources'] = infoField.replace(\"CLNDISDB=\",'')\n",
    "            \n",
    "            elif infoField.startswith('CLNDN='):\n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                clinvar_disease = infoField.replace(\"CLNDN=\",'')\n",
    "                if 'not_' in clinvar_disease:\n",
    "                    varDict[varID]['clinvarDisease'] = 'NA'\n",
    "                else:\n",
    "                    varDict[varID]['clinvarDisease'] = clinvar_disease\n",
    "            elif infoField.startswith('CLNSIG='): \n",
    "                # we can not move forward without identifying the varid\n",
    "                verifyVarID(varID, varID_alt)\n",
    "                \n",
    "                varDict[varID]['clinvarSignificance'] = infoField.replace(\"CLNSIG=\",'')\n",
    "\n",
    "\n",
    "            \n",
    "            '''    # Disabling as I could not find literature on this\n",
    "            elif infoField.startswith('dbNSFP_CADD_phred='):\n",
    "                varDict[varID]['CADD_phred'] = infoField.replace(\"dbNSFP_CADD_phred=\",'')\n",
    "            ''' \n",
    "  \n",
    "            \n",
    "            '''    # Reserved for the future updates\n",
    "            elif infoField.startswith('='): \n",
    "                varDict[varID][''] = infoField.replace(\"=\",'')\n",
    "            elif infoField.startswith('='): \n",
    "                varDict[varID][''] = infoField.replace(\"=\",'')\n",
    "            elif infoField.startswith('='): \n",
    "                varDict[varID][''] = infoField.replace(\"=\",'')\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "90d36cfa-1cea-4670-9691-b52807ce74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the concise_varDict by using the varDict\n",
    "\n",
    "#pathogenicity_keys = ['MutationTaster_pred', 'Polyphen2_HVAR_pred', 'Polyphen2_HDIV_pred', 'dbNSFP_PROVEAN_pred', 'dbNSFP_SIFT_pred', 'dbNSFP_MetaSVM_pred', 'dbNSFP_LRT_pred']\n",
    "#conservedness_keys = ['GERP_RS', 'phastCons100way_conservationScore']\n",
    "#popAF_keys = ['dbNSFP_ESP6500_AA_AF', ]\n",
    "#print(concise_varDict)\n",
    "\n",
    "\n",
    "highImpactVar_list = []\n",
    "pathogenicVar_list = []\n",
    "pathogenicityScore_dict = {}\n",
    "\n",
    "for varID in varDict:\n",
    "    \n",
    "    # set the defaults\n",
    "    concise_varDict[varID]['isSNP'] = 'False'\n",
    "    \n",
    "    # dnsnp\n",
    "    try:\n",
    "        concise_varDict[varID]['rsid'] = varDict[varID]['rsid']\n",
    "        concise_varDict[varID]['isSNP'] = 'True'\n",
    "    except KeyError:\n",
    "        concise_varDict[varID]['rsid'] = '-'\n",
    "    \n",
    "    # conservedness (this is a even a word?)\n",
    "    varConservedness = round(np.mean(varDict[varID]['conserved']), 2)\n",
    "\n",
    "    if str(varConservedness) == 'nan':\n",
    "        varConservedness = 'NA'\n",
    "        \n",
    "    # population AF\n",
    "    try:\n",
    "        varPopAF = max(varDict[varID]['popAF'])\n",
    "    except ValueError:\n",
    "        varPopAF = 0\n",
    "        \n",
    "    # Pathogenicity\n",
    "    varPathogenicity_list = varDict[varID]['pathogenicity']\n",
    "        \n",
    "    dCount = 0    # Count of 'D' as Damagin variant\n",
    "    tCount = 0    # Count of 'T' as Tolerated variant\n",
    "    uCount = 0    # Count of 'U' as Unknown variant pathogenicity\n",
    "        \n",
    "    for eachEffect in varPathogenicity_list:\n",
    "        if 'D' in eachEffect:\n",
    "            dCount += 1\n",
    "        elif 'T' in eachEffect:\n",
    "            tCount += 1\n",
    "        else:\n",
    "            uCount += 1\n",
    "    pathogenicity_finalTerm = \"D%sT%sU%s\" %(dCount,\n",
    "                                            tCount,\n",
    "                                            uCount)\n",
    "    if dCount+uCount+tCount == 0:\n",
    "        pathgenicity_finalScore = 0\n",
    "    else:\n",
    "        pathgenicity_finalScore = round((dCount+1)/float(tCount + 1), 4)\n",
    "        \n",
    "    # update concise_varDict\n",
    "    concise_varDict[varID]['conserved'] = varConservedness\n",
    "    concise_varDict[varID]['popAF'] = round(varPopAF, 4)\n",
    "\n",
    "    if varPopAF >= .02:\n",
    "        concise_varDict[varID]['isSNP'] = 'True'\n",
    "    concise_varDict[varID]['pathogenicity_occurances'] = pathogenicity_finalTerm\n",
    "    concise_varDict[varID]['pathogenicity_score'] = pathgenicity_finalScore\n",
    "    \n",
    "    # clinvar stuff; this is very important\n",
    "    try:\n",
    "        concise_varDict[varID]['clinvarID'] = varDict[varID]['clinvarID']\n",
    "        concise_varDict[varID]['clinvarDisease'] = varDict[varID]['clinvarDisease']\n",
    "        concise_varDict[varID]['clinvarSignificance'] = varDict[varID]['clinvarSignificance']\n",
    "        if 'pathogenic' in varDict[varID]['clinvarSignificance']:\n",
    "            pathogenicVar_list.append(varID)\n",
    "    except KeyError:\n",
    "        concise_varDict[varID]['clinvarID'] = 'NA'\n",
    "        concise_varDict[varID]['clinvarDisease'] = 'NA'\n",
    "        concise_varDict[varID]['clinvarSignificance'] = 'NA'\n",
    "    \n",
    "    # Update the significant variant data\n",
    "    if 'high' in varDict[varID]['impact'].lower():\n",
    "        highImpactVar_list.append(varID)\n",
    "    \n",
    "    try:\n",
    "        pathogenicityScore_dict[pathgenicity_finalScore].append(varID)\n",
    "    except KeyError:\n",
    "        pathogenicityScore_dict[pathgenicity_finalScore] = [varID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "245c0ad2-7bdc-4063-8951-2f55c41a0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's dump to the json\n",
    "#varDict = {}\n",
    "#concise_varDict = {}\n",
    "\n",
    "varDict_opath = \"%s/%s\" %(odir, os.path.basename(iVCF).replace('.vcf','.full.json'))\n",
    "conciseVarDict_opath = \"%s/%s\" %(odir, os.path.basename(iVCF).replace('.vcf','.concise.json'))\n",
    "\n",
    "with open(varDict_opath, 'w+') as vdf:\n",
    "    json.dump(varDict, vdf, indent = 4)\n",
    "    \n",
    "with open(conciseVarDict_opath, 'w+') as cvdf:\n",
    "    json.dump(concise_varDict, cvdf, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "94e3938b-edc1-42fe-be6e-a3a9845601d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the variants by their pathoginicity\n",
    "\n",
    "pathogenicVariants = ['#CHR\\tPOS\\tcdot\\taminoAcidAlteration\\tpredictedPathogenicity\\tImpact\\tconservedness\\tClinvarSignificance\\tClinvarDisease\\tdomainInfo']\n",
    "for pathogenicityScore in sorted(pathogenicityScore_dict.keys(), reverse=True):\n",
    "    #print(\"==\", pathogenicityScore)\n",
    "    #print(pathogenicityScore_dict[pathogenicityScore])\n",
    "    \n",
    "    \n",
    "    variantList = pathogenicityScore_dict[pathogenicityScore]\n",
    "    \n",
    "    for eachVar in variantList:\n",
    "        \n",
    "        # DO NOT DISCARD CLINVAR REPORTED VARIANTS\n",
    "        isPathogenic = False\n",
    "        if 'Pathogenic' in concise_varDict[eachVar][\"clinvarSignificance\"]:\n",
    "            isPathogenic = True\n",
    "\n",
    "        if 'True' in concise_varDict[eachVar][\"isSNP\"] and (not isPathogenic):\n",
    "            continue\n",
    "\n",
    "        if pathogenicityScore < 1.0 and (not isPathogenic):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            domainInfo = concise_varDict[eachVar][\"Interpro_domain\"]\n",
    "        except KeyError:\n",
    "            domainInfo = '-'\n",
    "        \n",
    "        varImpact = concise_varDict[eachVar][\"impact\"]\n",
    "        \n",
    "        # filter variants of less importance\n",
    "        if (not varImpact == 'HIGH') and (pathogenicityScore < 3) and (domainInfo == '-') and (not isPathogenic):\n",
    "            continue\n",
    "          \n",
    "        pathogenicVariants.append(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\" %(concise_varDict[eachVar][\"chrom\"],\n",
    "                                 concise_varDict[eachVar][\"gpos\"],\n",
    "                                 eachVar,\n",
    "                                 concise_varDict[eachVar][\"pdot\"].replace(\"p.\",\"\"),\n",
    "                                 pathogenicityScore,\n",
    "                                 varImpact,\n",
    "                                 concise_varDict[eachVar][\"conserved\"],\n",
    "                                 concise_varDict[eachVar][\"clinvarSignificance\"],\n",
    "                                 concise_varDict[eachVar][\"clinvarDisease\"],\n",
    "                                 domainInfo))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "31825c54-9328-49d0-a903-235c76c5f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathogenicVars_opath = \"%s/%s\" %(odir, os.path.basename(iVCF).replace('.vcf','.pathogenicVars.tsv'))\n",
    "writePathogenicVars_FH = open(pathogenicVars_opath, 'w+') \n",
    "writePathogenicVars_FH.write(\"\\n\".join(pathogenicVariants))\n",
    "writePathogenicVars_FH.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1e2ff-ab8c-436d-a845-7912d83d8129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
